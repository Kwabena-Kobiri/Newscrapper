{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "hollow-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "foreign-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "undefined-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "minor-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-158-ea198a19fe43>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('../../SETUPS/chromedriver_win32/chromedriver')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650\n",
      "Found one at iteration 2650 and index3\n",
      "2700\n",
      "2750\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#url of the page we want to scrape\n",
    "url = \"https://www.graphic.com.gh/news.html\"\n",
    "  \n",
    "# initiating the webdriver. Parameter includes the path of the webdriver.\n",
    "driver = webdriver.Chrome('../../SETUPS/chromedriver_win32/chromedriver') \n",
    "\n",
    "term = 'tidal waves'\n",
    "Titles = []\n",
    "Dates = []\n",
    "Links = []\n",
    "count = 0\n",
    "\n",
    "for i in range(2650, 57300, 50):\n",
    "    # print(i)\n",
    "    try:\n",
    "        url = f\"https://www.graphic.com.gh/news.html?start={i}\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        form = soup.find('form', {'id':'adminForm'})\n",
    "        newsItems = form.tbody.find_all('tr')\n",
    "        \n",
    "        for j in range(len(newsItems)):\n",
    "            Item = newsItems[j].find_all('td')\n",
    "            Title = Item[0].a.text\n",
    "            Date = Item[1].text\n",
    "            Link = Item[0].a['href']\n",
    "            \n",
    "            if term in Title.lower():\n",
    "                Titles.append(Title)\n",
    "                Dates.append(Date)\n",
    "                Links.append(Link)\n",
    "                count+=1\n",
    "                print(f\"Found one at iteration {i} and index{j}\")\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "                        \n",
    "print(count)  \n",
    "  \n",
    "driver.close() # closing the webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "hearing-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
